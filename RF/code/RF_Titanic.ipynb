{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data \n",
    "train = pd.read_csv(\"F:/postguaduate/Machine Learning/Titanic/train.csv\")\n",
    "test = pd.read_csv(\"F:/postguaduate/Machine Learning/Titanic/test.csv\")\n",
    "target='Survived' # Disbursed的值就是二元分类的输出\n",
    "IDcol = 'PassengerId'\n",
    "train.head() #查看数据集内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Age  SibSp  Parch  Fare  C  Q  S  Child  Female  Male  Class_1  \\\n",
       "0         0   22      1      0     7  0  0  1      0       0     1        0   \n",
       "1         1   38      1      0    71  1  0  0      0       1     0        1   \n",
       "2         1   26      0      0     7  0  0  1      0       1     0        0   \n",
       "3         1   35      1      0    53  0  0  1      0       1     0        1   \n",
       "4         0   35      0      0     8  0  0  1      0       0     1        0   \n",
       "\n",
       "   Class_2  Class_3  \n",
       "0        0        1  \n",
       "1        0        0  \n",
       "2        0        1  \n",
       "3        0        0  \n",
       "4        0        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###数据预处理\n",
    "\n",
    "###抛弃无关数据\n",
    "train = train.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "test = test.drop(['Name','Ticket','Cabin'], axis=1)\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "\n",
    "###Fare\n",
    "train['Fare'] = train['Fare'].astype(int)   #float 2 int\n",
    "test.Fare.fillna(test.Fare.median(), inplace=True)   #插补缺失数据\n",
    "test['Fare'] = test['Fare'].astype(int)\n",
    "\n",
    "\n",
    "###Embarked\n",
    "embark_dummies_train  = pd.get_dummies(train['Embarked'])     # pd.get_dummies()方法对离散数据重新编码，生成0-1矩阵\n",
    "embark_dummies_test  = pd.get_dummies(test['Embarked'])\n",
    "train = train.join(embark_dummies_train)   #合并矩阵\n",
    "test = test.join(embark_dummies_test)\n",
    "train.drop(['Embarked'], axis=1,inplace=True)   #删除原来的Embark列，inplace=Ture\n",
    "test.drop(['Embarked'], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "###Age 主要是对缺失的值进行处理填补\n",
    "average_age_titanic   = train[\"Age\"].mean()\n",
    "std_age_titanic       = train[\"Age\"].std()\n",
    "count_nan_age_titanic = train[\"Age\"].isnull().sum()\n",
    "\n",
    "average_age_test   = test[\"Age\"].mean()\n",
    "std_age_test       = test[\"Age\"].std()\n",
    "count_nan_age_test = test[\"Age\"].isnull().sum()\n",
    "\n",
    "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
    "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
    "train[\"Age\"][np.isnan(train[\"Age\"])] = rand_1    \n",
    "test[\"Age\"][np.isnan(test[\"Age\"])] = rand_2\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "test['Age']  = test['Age'].astype(int)\n",
    "\n",
    "\n",
    "###Sex  考虑到小孩及妇女优先对待，分三类\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return \"child\" if age < 16 else sex\n",
    "\n",
    "train['Person'] = train[['Age','Sex']].apply(get_person,axis=1)\n",
    "test['Person']  = test[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "train.drop(['Sex'],axis=1,inplace=True)\n",
    "test.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "person_dummies_titanic  = pd.get_dummies(train['Person'])\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test['Person'])\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "\n",
    "train = train.join(person_dummies_titanic)\n",
    "test = test.join(person_dummies_test)\n",
    "train.drop(['Person'],axis=1,inplace=True)\n",
    "test.drop(['Person'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "###P class\n",
    "pclass_dummies_titanic  = pd.get_dummies(train['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "\n",
    "train.drop(['Pclass'],axis=1,inplace=True)\n",
    "test.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train = train.join(pclass_dummies_titanic)\n",
    "test= test.join(pclass_dummies_test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [x for x in train.columns if x not in [target, IDcol]]\n",
    "X = train[x_columns]\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901234567901234\n",
      "AUC Score (Train): 0.990773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rf0.fit(X,y)\n",
    "print (rf0.oob_score_)\n",
    "y_predprob = rf0.predict_proba(X)[:,1]\n",
    "print( \"AUC Score (Train): %f\" % metrics.roc_auc_score(y, y_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.85374, std: 0.03691, params: {'n_estimators': 10},\n",
       "  mean: 0.86201, std: 0.03205, params: {'n_estimators': 20},\n",
       "  mean: 0.86407, std: 0.03372, params: {'n_estimators': 30},\n",
       "  mean: 0.86522, std: 0.03448, params: {'n_estimators': 40},\n",
       "  mean: 0.86579, std: 0.03435, params: {'n_estimators': 50},\n",
       "  mean: 0.86530, std: 0.03501, params: {'n_estimators': 60},\n",
       "  mean: 0.86478, std: 0.03549, params: {'n_estimators': 70}],\n",
       " {'n_estimators': 50},\n",
       " 0.8657887782110725)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##对n_estimate进行调优\n",
    "param_test1 = {'n_estimators':range(10,71,10)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=2,\n",
    "                                  min_samples_leaf=1,max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.85944, std: 0.01824, params: {'max_depth': 3, 'min_samples_split': 2},\n",
       "  mean: 0.85944, std: 0.01824, params: {'max_depth': 3, 'min_samples_split': 3},\n",
       "  mean: 0.85944, std: 0.01824, params: {'max_depth': 3, 'min_samples_split': 4},\n",
       "  mean: 0.85944, std: 0.01824, params: {'max_depth': 3, 'min_samples_split': 5},\n",
       "  mean: 0.85944, std: 0.01840, params: {'max_depth': 3, 'min_samples_split': 6},\n",
       "  mean: 0.85947, std: 0.01839, params: {'max_depth': 3, 'min_samples_split': 7},\n",
       "  mean: 0.85947, std: 0.01839, params: {'max_depth': 3, 'min_samples_split': 8},\n",
       "  mean: 0.85947, std: 0.01839, params: {'max_depth': 3, 'min_samples_split': 9},\n",
       "  mean: 0.86404, std: 0.02896, params: {'max_depth': 5, 'min_samples_split': 2},\n",
       "  mean: 0.86513, std: 0.03018, params: {'max_depth': 5, 'min_samples_split': 3},\n",
       "  mean: 0.86417, std: 0.03008, params: {'max_depth': 5, 'min_samples_split': 4},\n",
       "  mean: 0.86362, std: 0.02962, params: {'max_depth': 5, 'min_samples_split': 5},\n",
       "  mean: 0.86558, std: 0.03018, params: {'max_depth': 5, 'min_samples_split': 6},\n",
       "  mean: 0.86413, std: 0.02955, params: {'max_depth': 5, 'min_samples_split': 7},\n",
       "  mean: 0.86438, std: 0.02931, params: {'max_depth': 5, 'min_samples_split': 8},\n",
       "  mean: 0.86471, std: 0.02838, params: {'max_depth': 5, 'min_samples_split': 9},\n",
       "  mean: 0.86439, std: 0.03410, params: {'max_depth': 7, 'min_samples_split': 2},\n",
       "  mean: 0.86750, std: 0.03630, params: {'max_depth': 7, 'min_samples_split': 3},\n",
       "  mean: 0.86673, std: 0.03547, params: {'max_depth': 7, 'min_samples_split': 4},\n",
       "  mean: 0.86833, std: 0.03469, params: {'max_depth': 7, 'min_samples_split': 5},\n",
       "  mean: 0.86512, std: 0.03159, params: {'max_depth': 7, 'min_samples_split': 6},\n",
       "  mean: 0.86726, std: 0.03287, params: {'max_depth': 7, 'min_samples_split': 7},\n",
       "  mean: 0.86482, std: 0.03505, params: {'max_depth': 7, 'min_samples_split': 8},\n",
       "  mean: 0.86628, std: 0.03421, params: {'max_depth': 7, 'min_samples_split': 9},\n",
       "  mean: 0.86213, std: 0.03354, params: {'max_depth': 9, 'min_samples_split': 2},\n",
       "  mean: 0.86052, std: 0.03669, params: {'max_depth': 9, 'min_samples_split': 3},\n",
       "  mean: 0.86149, std: 0.03829, params: {'max_depth': 9, 'min_samples_split': 4},\n",
       "  mean: 0.86343, std: 0.03639, params: {'max_depth': 9, 'min_samples_split': 5},\n",
       "  mean: 0.86498, std: 0.03458, params: {'max_depth': 9, 'min_samples_split': 6},\n",
       "  mean: 0.86595, std: 0.03498, params: {'max_depth': 9, 'min_samples_split': 7},\n",
       "  mean: 0.86453, std: 0.03819, params: {'max_depth': 9, 'min_samples_split': 8},\n",
       "  mean: 0.86227, std: 0.03673, params: {'max_depth': 9, 'min_samples_split': 9},\n",
       "  mean: 0.85495, std: 0.02992, params: {'max_depth': 11, 'min_samples_split': 2},\n",
       "  mean: 0.85302, std: 0.03309, params: {'max_depth': 11, 'min_samples_split': 3},\n",
       "  mean: 0.85837, std: 0.03501, params: {'max_depth': 11, 'min_samples_split': 4},\n",
       "  mean: 0.85997, std: 0.03815, params: {'max_depth': 11, 'min_samples_split': 5},\n",
       "  mean: 0.86174, std: 0.03636, params: {'max_depth': 11, 'min_samples_split': 6},\n",
       "  mean: 0.86093, std: 0.03327, params: {'max_depth': 11, 'min_samples_split': 7},\n",
       "  mean: 0.86212, std: 0.03529, params: {'max_depth': 11, 'min_samples_split': 8},\n",
       "  mean: 0.86391, std: 0.03369, params: {'max_depth': 11, 'min_samples_split': 9},\n",
       "  mean: 0.83923, std: 0.03232, params: {'max_depth': 13, 'min_samples_split': 2},\n",
       "  mean: 0.84668, std: 0.03006, params: {'max_depth': 13, 'min_samples_split': 3},\n",
       "  mean: 0.85381, std: 0.03199, params: {'max_depth': 13, 'min_samples_split': 4},\n",
       "  mean: 0.85811, std: 0.03719, params: {'max_depth': 13, 'min_samples_split': 5},\n",
       "  mean: 0.85840, std: 0.03280, params: {'max_depth': 13, 'min_samples_split': 6},\n",
       "  mean: 0.85920, std: 0.03583, params: {'max_depth': 13, 'min_samples_split': 7},\n",
       "  mean: 0.86096, std: 0.03283, params: {'max_depth': 13, 'min_samples_split': 8},\n",
       "  mean: 0.86410, std: 0.03356, params: {'max_depth': 13, 'min_samples_split': 9}],\n",
       " {'max_depth': 7, 'min_samples_split': 5},\n",
       " 0.8683257805062047)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##上一步得到了最佳迭代次数为50 对max_depth和min_sample_split进行调优\n",
    "param_test2 = {'max_depth':range(3,14,2), 'min_samples_split':range(2,10,1)}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 50, \n",
    "                                  min_samples_leaf=1,max_features='sqrt' ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8159371492704826\n"
     ]
    }
   ],
   "source": [
    "#现在看看模型的袋外分数\n",
    "rf1 = RandomForestClassifier(n_estimators=50, max_depth=7, min_samples_split=5,min_samples_leaf=1,max_features='sqrt' ,oob_score=True,random_state=10)\n",
    "rf1.fit(X,y)\n",
    "print(rf1.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rf1.predict(test.drop('PassengerId',axis=1))\n",
    "my_submission =pd.DataFrame({'PassengerId': test['PassengerId'].as_matrix(),'Survived': Y_pred.astype(np.int32)})\n",
    "my_submission.to_csv(\"F:/postguaduate/Machine Learning/Titanic/my_submission_rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
